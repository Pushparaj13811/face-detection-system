{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%pip install pyheif --no-cache-dir\n",
    "%pip install pyheif pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple encoding for fast performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import faiss\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "DATASET_DIR = \"dataset_images\"\n",
    "\n",
    "embeddings = []\n",
    "metadata = []\n",
    "\n",
    "# Function to convert HEIC to JPEG if required\n",
    "def convert_heic_to_jpeg(image_path):\n",
    "    try:\n",
    "        from pillow_heif import register_heif_opener\n",
    "        register_heif_opener()\n",
    "        img = Image.open(image_path)\n",
    "        new_path = image_path.rsplit(\".\", 1)[0] + \".jpg\"\n",
    "        img.save(new_path, \"JPEG\")\n",
    "        print(f\"Converted HEIC to JPEG: {new_path}\")\n",
    "        return new_path\n",
    "    except ImportError:\n",
    "        print(\"Install pillow-heif for HEIC support: pip install pillow-heif\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting HEIC image: {image_path} - {e}\")\n",
    "        return None\n",
    "    \n",
    "for filename in os.listdir(DATASET_DIR):\n",
    "    image_path = os.path.join(DATASET_DIR, filename)\n",
    "\n",
    "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".heic\")):\n",
    "        print(f\"Skipping non-image file: {filename}\")\n",
    "        continue\n",
    "\n",
    "    if filename.lower().endswith(\".heic\"):\n",
    "        new_image_path = convert_heic_to_jpeg(image_path)\n",
    "        if new_image_path is None:\n",
    "            continue\n",
    "        image_path = new_image_path\n",
    "\n",
    "    try:\n",
    "        image = face_recognition.load_image_file(image_path)\n",
    "        face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "        if face_encodings:\n",
    "            print(f\"Detected {len(face_encodings)} face(s) in {filename}\")\n",
    "            embeddings.append(face_encodings[0])\n",
    "            metadata.append(filename)\n",
    "        else:\n",
    "            print(f\"No faces detected in {filename}. Skipping...\")\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Skipping unreadable image file: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "if embeddings:\n",
    "    embeddings = np.array(embeddings)\n",
    "\n",
    "    embedding_dim = 128\n",
    "    index = faiss.IndexFlatL2(embedding_dim)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    faiss.write_index(index, \"face_index.bin\")\n",
    "    np.save(\"metadata.npy\", np.array(metadata))\n",
    "\n",
    "    print(f\"Stored {len(embeddings)} embeddings in FAISS.\")\n",
    "else:\n",
    "    print(\"No valid face embeddings found. Index creation skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTCNN Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted HEIC to JPEG: dataset_images/IMG_9323.jpg\n",
      "Detected 1 face(s) in IMG_9323.HEIC\n",
      "Converted HEIC to JPEG: dataset_images/IMG_0253 2.jpg\n",
      "Detected 9 face(s) in IMG_0253 2.heic\n",
      "Converted HEIC to JPEG: dataset_images/IMG_0417.jpg\n",
      "Detected 3 face(s) in IMG_0417.heic\n",
      "Detected 7 face(s) in IMG_6620 2.JPG\n",
      "Detected 6 face(s) in FullSizeRender 37.JPG\n",
      "Detected 13 face(s) in FullSizeRender 23.JPG\n",
      "Converted HEIC to JPEG: dataset_images/IMG_0381.jpg\n",
      "Detected 1 face(s) in IMG_0381.heic\n",
      "Detected 1 face(s) in 401eed72ad2db46fd0bc927e2b3d8e4a.jpg\n",
      "Detected 4 face(s) in IMG_4919.JPG\n",
      "Detected 2 face(s) in IMG_3567.jpeg\n",
      "Detected 1 face(s) in images (30).jpeg\n",
      "Detected 2 face(s) in IMG_4925.JPG\n",
      "Detected 11 face(s) in IMG_0216.jpg\n",
      "Converted HEIC to JPEG: dataset_images/IMG_0339.jpg\n",
      "Detected 10 face(s) in IMG_0339.heic\n",
      "Converted HEIC to JPEG: dataset_images/IMG_0293.jpg\n",
      "Detected 3 face(s) in IMG_0293.heic\n",
      "Detected 1 face(s) in images (2).jpeg\n",
      "No faces detected in pexels-codioful-7130560.jpg. Skipping...\n",
      "Detected 1 face(s) in download.jpeg\n",
      "Detected 2 face(s) in IMG_0389.jpg\n",
      "Detected 13 face(s) in IMG_0255 2.jpg\n",
      "Converted HEIC to JPEG: dataset_images/IMG_0285.jpg\n",
      "Detected 1 face(s) in IMG_0285.heic\n",
      "Detected 7 face(s) in IMG_0362.jpg\n",
      "Detected 3 face(s) in IMG_6713.JPG\n",
      "Detected 1 face(s) in WhatsApp Image 2024-07-17 at 3.13.28 PM (1).jpeg\n",
      "Detected 7 face(s) in IMG_0404.jpg\n",
      "Detected 4 face(s) in IMG_0410.jpg\n",
      "Detected 7 face(s) in IMG_0376.jpg\n",
      "Converted HEIC to JPEG: dataset_images/IMG_0114.jpg\n",
      "Detected 2 face(s) in IMG_0114.HEIC\n",
      "Converted HEIC to JPEG: dataset_images/IMG_0401.jpg\n",
      "Detected 1 face(s) in IMG_0401.heic\n",
      "Converted HEIC to JPEG: dataset_images/IMG_0378.jpg\n",
      "Detected 1 face(s) in IMG_0378.heic\n",
      "No faces detected in IMG_6505.jpg. Skipping...\n",
      "Detected 7 face(s) in IMG_0174.jpg\n",
      "Converted HEIC to JPEG: dataset_images/IMG_0222 2.jpg\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import faiss\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "DATASET_DIR = \"dataset_images\"\n",
    "\n",
    "embeddings = []\n",
    "metadata = []\n",
    "\n",
    "# Initialize MTCNN detector\n",
    "mtcnn_detector = MTCNN()\n",
    "\n",
    "# Function to convert HEIC to JPEG if required\n",
    "def convert_heic_to_jpeg(image_path):\n",
    "    try:\n",
    "        from pillow_heif import register_heif_opener\n",
    "        register_heif_opener()\n",
    "        img = Image.open(image_path)\n",
    "        new_path = image_path.rsplit(\".\", 1)[0] + \".jpg\"\n",
    "        img.save(new_path, \"JPEG\")\n",
    "        print(f\"Converted HEIC to JPEG: {new_path}\")\n",
    "        return new_path\n",
    "    except ImportError:\n",
    "        print(\"Install pillow-heif for HEIC support: pip install pillow-heif\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting HEIC image: {image_path} - {e}\")\n",
    "        return None\n",
    "\n",
    "for filename in os.listdir(DATASET_DIR):\n",
    "    image_path = os.path.join(DATASET_DIR, filename)\n",
    "\n",
    "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".heic\")):\n",
    "        print(f\"Skipping non-image file: {filename}\")\n",
    "        continue\n",
    "\n",
    "    if filename.lower().endswith(\".heic\"):\n",
    "        new_image_path = convert_heic_to_jpeg(image_path)\n",
    "        if new_image_path is None:\n",
    "            continue\n",
    "        image_path = new_image_path\n",
    "\n",
    "    try:\n",
    "        # Load the image\n",
    "        image = face_recognition.load_image_file(image_path)\n",
    "        \n",
    "        # Detect faces using MTCNN\n",
    "        faces = mtcnn_detector.detect_faces(image)\n",
    "        \n",
    "        if faces:\n",
    "            print(f\"Detected {len(faces)} face(s) in {filename}\")\n",
    "            for face in faces:\n",
    "                # Get the bounding box of the face\n",
    "                x, y, width, height = face['box']\n",
    "                \n",
    "                # Extract the face from the image using the bounding box\n",
    "                face_image = image[y:y + height, x:x + width]\n",
    "                \n",
    "                # Get the face encoding using the bounding box from MTCNN\n",
    "                face_locations = [(y, x + width, y + height, x)]  # Format for face_recognition\n",
    "                face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "                \n",
    "                if face_encodings:\n",
    "                    embeddings.append(face_encodings[0])\n",
    "                    metadata.append(filename)\n",
    "                else:\n",
    "                    print(f\"No face encoding found in {filename}. Skipping...\")\n",
    "        else:\n",
    "            print(f\"No faces detected in {filename}. Skipping...\")\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Skipping unreadable image file: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "if embeddings:\n",
    "    embeddings = np.array(embeddings)\n",
    "\n",
    "    embedding_dim = 128\n",
    "    index = faiss.IndexFlatL2(embedding_dim)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    faiss.write_index(index, \"face_index.bin\")\n",
    "    np.save(\"metadata.npy\", np.array(metadata))\n",
    "    print(f\"Stored {len(embeddings)} embeddings in FAISS.\")\n",
    "else:\n",
    "    print(\"No valid face embeddings found. Index creation skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import faiss\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = faiss.read_index(\"face_index.bin\")\n",
    "metadata = np.load(\"metadata.npy\")\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "def display_image(image, title=\"Image\"):\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title, fontsize=14, color='blue')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def upload_image():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = cv2.imread(file_path)\n",
    "        return img\n",
    "    return None\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Press 'C' to capture an image using webcam.\")\n",
    "print(\"Press 'U' to upload an image from your file system.\")\n",
    "print(\"Press 'Q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Video Feed\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord(\"c\"):\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "\n",
    "        if face_locations:\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "            for face_encoding in face_encodings:\n",
    "                face_encoding = np.array([face_encoding])\n",
    "                distances, indices = index.search(face_encoding, k=len(metadata))\n",
    "\n",
    "                matches = []\n",
    "                for i, distance in enumerate(distances[0]):\n",
    "                    if distance < THRESHOLD:\n",
    "                        matches.append((metadata[indices[0][i]], distance))\n",
    "\n",
    "                if matches:\n",
    "                    person_matches = {}\n",
    "                    for match_filename, match_distance in matches:\n",
    "                        person_id = match_filename.split(\"_\")[0]\n",
    "                        if person_id not in person_matches:\n",
    "                            person_matches[person_id] = []\n",
    "                        person_matches[person_id].append(match_distance)\n",
    "\n",
    "                    valid_persons = []\n",
    "                    for person_id, distances in person_matches.items():\n",
    "                        avg_distance = np.mean(distances)\n",
    "                        if avg_distance < THRESHOLD:\n",
    "                            valid_persons.append(person_id)\n",
    "\n",
    "                    if valid_persons:\n",
    "                        print(f\"Found matches for: {', '.join(valid_persons)}\")\n",
    "                        for person_id in valid_persons:\n",
    "                            for match_filename, match_distance in matches:\n",
    "                                if match_filename.startswith(person_id):\n",
    "                                    accuracy_score = (1 - match_distance) * 100\n",
    "                                    print(f\"  - {match_filename} (Distance: {match_distance}, Accuracy: {accuracy_score:.2f}%)\")\n",
    "                                    matched_image_path = f\"dataset_images/{match_filename}\"\n",
    "                                    matched_img = cv2.imread(matched_image_path)\n",
    "                                    if matched_img is not None:\n",
    "                                        display_image(matched_img,f\"Matched: {match_filename}\\nAccuracy: {accuracy_score:.2f}%\",)\n",
    "                    else:\n",
    "                        print(\"No relevant matches found. Please try again.\")\n",
    "                else:\n",
    "                    print(\"No relevant matches found. Please try again.\")\n",
    "        else:\n",
    "            print(\"No face detected in the captured image.\")\n",
    "\n",
    "    elif key == ord(\"u\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        uploaded_img = upload_image()\n",
    "        if uploaded_img is not None:\n",
    "            rgb_image = cv2.cvtColor(uploaded_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            face_locations = face_recognition.face_locations(rgb_image)\n",
    "\n",
    "            if face_locations:\n",
    "                face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "                for face_encoding in face_encodings:\n",
    "                    face_encoding = np.array([face_encoding])\n",
    "                    distances, indices = index.search(face_encoding, k=len(metadata))\n",
    "\n",
    "                    matches = []\n",
    "                    for i, distance in enumerate(distances[0]):\n",
    "                        if distance < THRESHOLD:\n",
    "                            matches.append((metadata[indices[0][i]], distance))\n",
    "\n",
    "                    if matches:\n",
    "                        person_matches = {}\n",
    "                        for match_filename, match_distance in matches:\n",
    "                            person_id = match_filename.split(\"_\")[0]\n",
    "                            if person_id not in person_matches:\n",
    "                                person_matches[person_id] = []\n",
    "                            person_matches[person_id].append(match_distance)\n",
    "\n",
    "                        valid_persons = []\n",
    "                        for person_id, distances in person_matches.items():\n",
    "                            avg_distance = np.mean(distances)\n",
    "                            if avg_distance < THRESHOLD:\n",
    "                                valid_persons.append(person_id)\n",
    "\n",
    "                        if valid_persons:\n",
    "                            print(f\"Found matches for: {', '.join(valid_persons)}\")\n",
    "                            for person_id in valid_persons:\n",
    "                                for match_filename, match_distance in matches:\n",
    "                                    if match_filename.startswith(person_id):\n",
    "                                        print(f\"  - {match_filename} (Distance: {match_distance})\")\n",
    "                                        matched_image_path = f\"dataset_images/{match_filename}\"\n",
    "                                        matched_img = cv2.imread(matched_image_path)\n",
    "                                        if matched_img is not None:\n",
    "                                            display_image(matched_img, f\"Matched: {match_filename}\")\n",
    "                        else:\n",
    "                            print(\"No relevant matches found. Please try again.\")\n",
    "                    else:\n",
    "                        print(\"No relevant matches found. Please try again.\")\n",
    "            else:\n",
    "                print(\"No face detected in the uploaded image.\")\n",
    "        else:\n",
    "            print(\"No image uploaded. Please try again.\")\n",
    "\n",
    "    elif key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
